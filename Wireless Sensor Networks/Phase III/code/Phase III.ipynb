{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Bayesian Net with spatial and temporal correlations among sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import os as os\n",
    "from sklearn.linear_model import Lasso\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "import helpers\n",
    "import inspect\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_matrix(file_path):    \n",
    "    '''Strip out the first row and first column and return data matrix'''\n",
    "    data = np.loadtxt(file_path, delimiter=',', skiprows=1)\n",
    "    return data[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class sensor(object):\n",
    "    \"\"\" A sensor.\n",
    "    Parameters after training are:\n",
    "    1. Mu_i,Sigma_i\n",
    "    2. 51 Betas\n",
    "    3. Conditional Variance\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,total_sensors):        \n",
    "        #For compute_initial_mu_vars\n",
    "        self.mu_i = -1\n",
    "        self.var_i = -1    \n",
    "        \n",
    "        #For compute_betas\n",
    "        self.betas = [-1 for i in range(total_sensors+1)]\n",
    "        \n",
    "        #For compute_cond_var\n",
    "        self.cond_var = -1\n",
    "    \n",
    "    def compute_initial_mu_vars(self,sensors_readings):\n",
    "        self.mu_i = np.mean(sensors_readings)        \n",
    "        self.var_i = np.var(sensors_readings)\n",
    "    \n",
    "    def compute_betas(self,X,y):\n",
    "        self.regr = Lasso()\n",
    "        self.regr.fit(X, y)\n",
    "        self.betas[0] = self.regr.intercept_        \n",
    "        \n",
    "        for id,value in enumerate(self.regr.coef_):\n",
    "            self.betas[id+1] = value\n",
    "                \n",
    "        \n",
    "    def compute_cond_var(self,X,y):     \n",
    "        predictions = np.array([self.regr.predict(row)[0] for row in X])        \n",
    "        error = y - predictions        \n",
    "        self.cond_var = np.var(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def learn_train_params(train_data_path):\n",
    "    '''Train a lasso regressor on the train data and return the parameters of sensors'''\n",
    "    \n",
    "    data_matrix = get_data_matrix(train_data_path)\n",
    "    sensors_count = data_matrix.shape[0]\n",
    "    timestamps_count = data_matrix.shape[1]\n",
    "\n",
    "    sensor_obj_lst = []\n",
    "    X = data_matrix[:,:timestamps_count-1].T\n",
    "\n",
    "    for s_id in range(sensors_count):\n",
    "        sensor_obj = sensor(sensors_count)    \n",
    "        sensor_obj.compute_initial_mu_vars(data_matrix[s_id])    \n",
    "        y = data_matrix[s_id][1:].T\n",
    "        sensor_obj.compute_betas(X,y)\n",
    "        sensor_obj.compute_cond_var(X,y)\n",
    "        sensor_obj_lst.append(sensor_obj)\n",
    "        \n",
    "    return sensor_obj_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Window Sliding Active Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_pred_mat_using_sliding(old_test_mat,budget,sens_params_lst):\n",
    "    '''Predict the ones that are not in window. For the rest, use existing data'''\n",
    "    \n",
    "    test_matrix = old_test_mat.copy()\n",
    "    total_cols = test_matrix.shape[1]\n",
    "    total_rows = test_matrix.shape[0]\n",
    "\n",
    "    windows = helpers.get_windows(total_rows,total_cols,budget)\n",
    "\n",
    "    for col in range(0,total_cols):\n",
    "        \n",
    "        #Row Ids to be predicted\n",
    "        pred_row_ids = set(range(0,total_rows)) - set(windows[col])\n",
    "                \n",
    "        for r_id in pred_row_ids:\n",
    "            current_sensor = sens_params_lst[r_id]\n",
    "            if col == 0:\n",
    "                test_matrix[r_id,col] = current_sensor.mu_i\n",
    "            else:\n",
    "                betas = current_sensor.betas\n",
    "                prev_col = test_matrix[:,col-1:col]\n",
    "                test_matrix[r_id,col] = betas[0]+ np.dot(betas[1:],prev_col)\n",
    "                    \n",
    "    return test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_predict(train_data_path,test_data_path,budget,Inf_type='W'):\n",
    "    \n",
    "    #Train to get params\n",
    "    sens_params_lst = learn_train_params(train_data_path)\n",
    "    \n",
    "    test_matrix = get_data_matrix(test_data_path)\n",
    "    \n",
    "    #Return prediction values obtained using train params\n",
    "    if Inf_type == 'W':\n",
    "        return build_pred_mat_using_sliding(test_matrix,budget,sens_params_lst)\n",
    "    elif Inf_type == 'V':\n",
    "        return build_pred_mat_using_var(test_matrix,sens_params_lst,budget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Temperature's MAE using Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3580283488\n",
      "1.40551284707\n",
      "0.963139344009\n",
      "0.507008480598\n",
      "0.388757264106\n"
     ]
    }
   ],
   "source": [
    "for budget in [0,5,10,20,25]:\n",
    "    pred_mat = train_and_predict('Dataset\\intelTemperatureTrain.csv','Dataset\\intelTemperatureTest.csv',budget,'W')\n",
    "    \n",
    "    'Write to disc [START]'\n",
    "    file_name = 'w'+str(budget)+'.csv'\n",
    "    row_ids = [x for x in range(0,50)] #50 sensors\n",
    "    col_ids = list(np.arange(0.5,24.5,0.5))\n",
    "    col_ids += col_ids\n",
    "    col_ids = [x if x!= 24 else 0 for x in col_ids]\n",
    "    df = pd.DataFrame(pred_mat, index=row_ids, columns=col_ids)\n",
    "    df.to_csv(file_name, index=True, header=True, sep=',')\n",
    "    'END'\n",
    "    \n",
    "    test_matrix = get_data_matrix('Dataset\\intelTemperatureTest.csv')\n",
    "    print helpers.mean_abs_error(test_matrix,pred_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Humidity's MAE using Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.20400735684\n",
      "2.91873540345\n",
      "1.71199837154\n",
      "0.823603812128\n",
      "0.563036486245\n"
     ]
    }
   ],
   "source": [
    "for budget in [0,5,10,20,25]:\n",
    "    pred_mat = train_and_predict('Dataset\\intelHumidityTrain.csv','Dataset\\intelHumidityTest.csv',budget,'W')\n",
    "    \n",
    "    'Write to disc [START]'\n",
    "    file_name = 'w'+str(budget)+'.csv'\n",
    "    row_ids = [x for x in range(0,50)] #50 sensors\n",
    "    col_ids = list(np.arange(0.5,24.5,0.5))\n",
    "    col_ids += col_ids\n",
    "    col_ids = [x if x!= 24 else 0 for x in col_ids]\n",
    "    df = pd.DataFrame(pred_mat, index=row_ids, columns=col_ids)\n",
    "    df.to_csv(file_name, index=True, header=True, sep=',')\n",
    "    'END'\n",
    "    \n",
    "    test_matrix = get_data_matrix('Dataset\\intelHumidityTest.csv')\n",
    "    print helpers.mean_abs_error(test_matrix,pred_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##Variance Based Active Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\sigma_{ij}=\\sigma_i + \\sum_{q=1}^{50} \\beta_{q}^{(i)^{2}} \\sigma_{q-2,j-1}$ <br>\n",
    "- $\\sigma_{i}$ is the conditional variance\n",
    "- $\\beta_{q}^{(i)}$ is the qth regressed coefficient of ith sensor\n",
    "- $\\sigma_{ij}$ is the variance at jth timestamp of ith sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_variance(col_id,sens_params,prev_col_vars=[]):\n",
    "    '''Compute the variance according to above formula. '''\n",
    "    \n",
    "    var = 0\n",
    "    \n",
    "    if col_id == 0 and prev_col_vars == []:\n",
    "        var = sens_params.var_i\n",
    "    elif prev_col_vars != []:        \n",
    "        cond_var = sens_params.cond_var\n",
    "        betas = sens_params.betas[1:]        \n",
    "        part2 = np.dot(betas,prev_col_vars)\n",
    "        var = cond_var + part2\n",
    "        \n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_pred_mat_using_var(test_matrix,sens_params,budget):\n",
    "    '''Build the predicted matrix using variance based approach'''\n",
    "    total_cols = test_matrix.shape[1]\n",
    "    total_rows = test_matrix.shape[0]\n",
    "    \n",
    "    variances_matrix = np.zeros((total_rows,total_cols))\n",
    "    prev_col_variances=[]\n",
    "    \n",
    "    for col_id in range(0,total_cols):\n",
    "        \n",
    "        #Get the variances of the column col_id\n",
    "        col_variances = []\n",
    "        for row in range(0,total_rows):\n",
    "            cur_sensor_params = sens_params[row]\n",
    "            var_ij = compute_variance(col_id,cur_sensor_params,prev_col_variances)\n",
    "            col_variances.append(var_ij)\n",
    "        \n",
    "        #Get the indices with top k variances     \n",
    "  \n",
    "        top_var_ind = helpers.top_k_indices(col_variances,budget)\n",
    "    \n",
    "        #For ones with top k variances, set variance to 0 as it won't be predicted\n",
    "        for ind in top_var_ind:\n",
    "            variances_matrix[ind,col_id] = 0\n",
    "        \n",
    "        pred_row_ids = set(range(0,total_rows)) - set(top_var_ind)\n",
    "        \n",
    "        #Predict the ones which do not fall among top k variances\n",
    "        for row_id in pred_row_ids:\n",
    "            #Update mu\n",
    "            current_sensor = sens_params[row_id]            \n",
    "            betas = current_sensor.betas\n",
    "            if col_id == 0:                      \n",
    "                test_matrix[row_id,col_id] = current_sensor.mu_i\n",
    "            else:\n",
    "                prev_col_mus = test_matrix[:,col_id-1:col_id]\n",
    "                test_matrix[row_id,col_id] = betas[0]+ np.dot(betas[1:],prev_col_mus)\n",
    "            \n",
    "            #Update sigmas\n",
    "            cur_sensor_params = sens_params[row_id]\n",
    "            if col_id == 0:\n",
    "                prev_col_vars_2 = None\n",
    "                variances_matrix[row_id,col_id]  = cur_sensor_params.var_i\n",
    "            else:\n",
    "                #prev_col_vars_2 = variances_matrix[:,col_id-1:col_id]                       \n",
    "                prev_col_vars_2 = []\n",
    "                \n",
    "                for ele in variances_matrix[:,col_id-1:col_id] :\n",
    "                    prev_col_vars_2.append(ele[0])\n",
    "        \n",
    "                variances_matrix[row_id,col_id] = compute_variance(col_id,cur_sensor_params,prev_col_vars_2)           \n",
    "        \n",
    "        prev_col_variances= []\n",
    "        for ele in variances_matrix[:,col_id:col_id+1]:\n",
    "            prev_col_variances.append(ele[0])\n",
    "            \n",
    "    return test_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Temperature's MAE using Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3580283488\n",
      "0.776612864088\n",
      "0.632531210788\n",
      "0.406946347889\n",
      "0.330723961793\n"
     ]
    }
   ],
   "source": [
    "for budget in [0,5,10,20,25]:\n",
    "    pred_mat = train_and_predict('Dataset\\intelTemperatureTrain.csv','Dataset\\intelTemperatureTest.csv',budget,'V')\n",
    "    \n",
    "    'Write to disc [START]'\n",
    "    file_name = 'v'+str(budget)+'.csv'\n",
    "    row_ids = [x for x in range(0,50)] #50 sensors\n",
    "    col_ids = list(np.arange(0.5,24.5,0.5))\n",
    "    col_ids += col_ids\n",
    "    col_ids = [x if x!= 24 else 0 for x in col_ids]\n",
    "    df = pd.DataFrame(pred_mat, index=row_ids, columns=col_ids)\n",
    "    df.to_csv(file_name, index=True, header=True, sep=',')\n",
    "    'END'\n",
    "    test_matrix = get_data_matrix('Dataset\\intelTemperatureTest.csv')\n",
    "    print helpers.mean_abs_error(test_matrix,pred_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Humidity's MAE using Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.20400735684\n",
      "2.09154217564\n",
      "1.4122045059\n",
      "0.842476668095\n",
      "0.633271897529\n"
     ]
    }
   ],
   "source": [
    "for budget in [0,5,10,20,25]:\n",
    "    pred_mat = train_and_predict('Dataset\\intelHumidityTrain.csv','Dataset\\intelHumidityTest.csv',budget,'V')\n",
    "    \n",
    "    'Write to disc [START]'\n",
    "    file_name = 'v'+str(budget)+'.csv'\n",
    "    row_ids = [x for x in range(0,50)] #50 sensors\n",
    "    col_ids = list(np.arange(0.5,24.5,0.5))\n",
    "    col_ids += col_ids\n",
    "    col_ids = [x if x!= 24 else 0 for x in col_ids]\n",
    "    df = pd.DataFrame(pred_mat, index=row_ids, columns=col_ids)\n",
    "    df.to_csv(file_name, index=True, header=True, sep=',')\n",
    "    'END'\n",
    "    \n",
    "    test_matrix = get_data_matrix('Dataset\\intelHumidityTest.csv')\n",
    "    print helpers.mean_abs_error(test_matrix,pred_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
